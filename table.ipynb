{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to sorted_metrics_summary.xlsx in the 'graph_pdc_off' directory with four decimal places for Median and IQR\n",
      "Final output saved as 'final_formatted_output.xlsx' in the 'graph_pdc_off' directory.\n"
     ]
    }
   ],
   "source": [
    "### pdc official \n",
    "\n",
    "\n",
    "# Necessary imports\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Ensure the directory exists\n",
    "output_dir = './graph_pdc_off'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load the updated CSV file\n",
    "file_path = './graph_pdc_off/combined_metrics_summary.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Multiply 'Median' and 'IQR' by 100 for better visibility, excluding r_sq\n",
    "metrics_to_scale = ['Median', 'IQR']\n",
    "for metric in metrics_to_scale:\n",
    "    data.loc[data['Metric'] != 'r_sq', metric] = data.loc[data['Metric'] != 'r_sq', metric] * 100\n",
    "\n",
    "# Round 'Median' and 'IQR' to four decimal places for better visibility\n",
    "data['Median'] = data['Median'].round(4)\n",
    "data['IQR'] = data['IQR'].round(4)\n",
    "\n",
    "# Sort the data by 'Metric', 'Horizon', and 'Median'\n",
    "sorted_data_per_metric = data.sort_values(by=['Metric', 'Horizon', 'Median']).reset_index(drop=True)\n",
    "\n",
    "# Group by 'Metric' and 'Horizon' and find the best model (minimum Median) for each metric and horizon combination\n",
    "best_models_per_metric_horizon = sorted_data_per_metric.loc[sorted_data_per_metric.groupby(['Metric', 'Horizon'])['Median'].idxmin()]\n",
    "\n",
    "# Save the outputs to an Excel file with two sheets, including the four-decimal rounded values\n",
    "output_path = f\"{output_dir}/sorted_metrics_summary.xlsx\"\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    sorted_data_per_metric.to_excel(writer, sheet_name='Sorted_Data', index=False)\n",
    "    best_models_per_metric_horizon.to_excel(writer, sheet_name='Best_Models', index=False)\n",
    "\n",
    "print(\"Data saved to sorted_metrics_summary.xlsx in the 'graph_pdc_off' directory with four decimal places for Median and IQR\")\n",
    "\n",
    "# Load the Excel file and read the \"Sorted_Data\" sheet\n",
    "file_path = './graph_pdc_off/sorted_metrics_summary.xlsx'  # Update this path if necessary\n",
    "sorted_data = pd.read_excel(file_path, sheet_name='Sorted_Data')\n",
    "\n",
    "# Define empty lists to populate the new table structure\n",
    "table_rows = []\n",
    "\n",
    "# Iterate over each unique model and horizon combination to create the formatted rows\n",
    "for model in sorted_data['Model'].unique():\n",
    "    row = [model]  # Start with the model name\n",
    "    for horizon in ['tau_1', 'tau_3', 'tau_6', 'tau_9']:  # Include tau_1, tau_3, tau_6, tau_9\n",
    "        # Filter data for the specific model and horizon\n",
    "        subset = sorted_data[(sorted_data['Model'] == model) & (sorted_data['Horizon'] == horizon)]\n",
    "        \n",
    "        # Extract RMSE, MAD, MAE, and R^2 if available\n",
    "        rmse_row = subset[subset['Metric'] == 'rmse']\n",
    "        mad_row = subset[subset['Metric'] == 'mad']\n",
    "        mae_row = subset[subset['Metric'] == 'mae']\n",
    "        r_sq_row = subset[subset['Metric'] == 'r_sq']\n",
    "        \n",
    "        # Format each cell as \"Median\\n(IQR)\" or empty if not available\n",
    "        rmse_value = f\"{rmse_row['Median'].values[0]:.4f}\\n({rmse_row['IQR'].values[0]:.4f})\" if not rmse_row.empty else \"\"\n",
    "        mad_value = f\"{mad_row['Median'].values[0]:.4f}\\n({mad_row['IQR'].values[0]:.4f})\" if not mad_row.empty else \"\"\n",
    "        mae_value = f\"{mae_row['Median'].values[0]:.4f}\\n({mae_row['IQR'].values[0]:.4f})\" if not mae_row.empty else \"\"\n",
    "        r_sq_value = f\"{r_sq_row['Median'].values[0]:.4f}\\n({r_sq_row['IQR'].values[0]:.4f})\" if not r_sq_row.empty else \"\"\n",
    "        \n",
    "        # Append combined Median\\n(IQR) values for this horizon\n",
    "        row.extend([rmse_value, mad_value, mae_value, r_sq_value])\n",
    "    \n",
    "    # Add the row to the table structure\n",
    "    table_rows.append(row)\n",
    "\n",
    "# Define the column headers, including R^2 for each horizon\n",
    "columns = [\n",
    "    \"Model\", \"RMSE (h=1)\", \"MAD (h=1)\", \"MAE (h=1)\", \"R^2 (h=1)\",\n",
    "    \"RMSE (h=3)\", \"MAD (h=3)\", \"MAE (h=3)\", \"R^2 (h=3)\", \n",
    "    \"RMSE (h=6)\", \"MAD (h=6)\", \"MAE (h=6)\", \"R^2 (h=6)\", \n",
    "    \"RMSE (h=9)\", \"MAD (h=9)\", \"MAE (h=9)\", \"R^2 (h=9)\"\n",
    "]\n",
    "\n",
    "# Create the formatted DataFrame\n",
    "formatted_table = pd.DataFrame(table_rows, columns=columns)\n",
    "\n",
    "# Define the output file path\n",
    "output_path = './graph_pdc_off/final_formatted_output.xlsx'  # Update this path if necessary\n",
    "\n",
    "# Save the formatted table to Excel\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    formatted_table.to_excel(writer, sheet_name='Formatted_Output', index=False)\n",
    "\n",
    "print(\"Final output saved as 'final_formatted_output.xlsx' in the 'graph_pdc_off' directory.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to sorted_metrics_summary.xlsx in the 'graph_pdc_off' directory with four decimal places for Median and IQR\n",
      "Final output saved as 'final_formatted_output.xlsx' in the 'graph_pdc_off' directory.\n"
     ]
    }
   ],
   "source": [
    "### pdc gt\n",
    "\n",
    "\n",
    "\n",
    "# Necessary imports\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Ensure the directory exists\n",
    "output_dir = './graph_pdc_gt'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load the updated CSV file\n",
    "file_path = './graph_pdc_gt/combined_metrics_summary.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Multiply 'Median' and 'IQR' by 100 for better visibility, excluding r_sq\n",
    "metrics_to_scale = ['Median', 'IQR']\n",
    "for metric in metrics_to_scale:\n",
    "    data.loc[data['Metric'] != 'r_sq', metric] = data.loc[data['Metric'] != 'r_sq', metric] * 100\n",
    "\n",
    "# Round 'Median' and 'IQR' to four decimal places for better visibility\n",
    "data['Median'] = data['Median'].round(4)\n",
    "data['IQR'] = data['IQR'].round(4)\n",
    "\n",
    "# Sort the data by 'Metric', 'Horizon', and 'Median'\n",
    "sorted_data_per_metric = data.sort_values(by=['Metric', 'Horizon', 'Median']).reset_index(drop=True)\n",
    "\n",
    "# Group by 'Metric' and 'Horizon' and find the best model (minimum Median) for each metric and horizon combination\n",
    "best_models_per_metric_horizon = sorted_data_per_metric.loc[sorted_data_per_metric.groupby(['Metric', 'Horizon'])['Median'].idxmin()]\n",
    "\n",
    "# Save the outputs to an Excel file with two sheets, including the four-decimal rounded values\n",
    "output_path = f\"{output_dir}/sorted_metrics_summary.xlsx\"\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    sorted_data_per_metric.to_excel(writer, sheet_name='Sorted_Data', index=False)\n",
    "    best_models_per_metric_horizon.to_excel(writer, sheet_name='Best_Models', index=False)\n",
    "\n",
    "print(\"Data saved to sorted_metrics_summary.xlsx in the 'graph_pdc_off' directory with four decimal places for Median and IQR\")\n",
    "\n",
    "# Load the Excel file and read the \"Sorted_Data\" sheet\n",
    "file_path = './graph_pdc_gt/sorted_metrics_summary.xlsx'  # Update this path if necessary\n",
    "sorted_data = pd.read_excel(file_path, sheet_name='Sorted_Data')\n",
    "\n",
    "# Define empty lists to populate the new table structure\n",
    "table_rows = []\n",
    "\n",
    "# Iterate over each unique model and horizon combination to create the formatted rows\n",
    "for model in sorted_data['Model'].unique():\n",
    "    row = [model]  # Start with the model name\n",
    "    for horizon in ['tau_1', 'tau_3', 'tau_6', 'tau_9']:  # Include tau_1, tau_3, tau_6, tau_9\n",
    "        # Filter data for the specific model and horizon\n",
    "        subset = sorted_data[(sorted_data['Model'] == model) & (sorted_data['Horizon'] == horizon)]\n",
    "        \n",
    "        # Extract RMSE, MAD, MAE, and R^2 if available\n",
    "        rmse_row = subset[subset['Metric'] == 'rmse']\n",
    "        mad_row = subset[subset['Metric'] == 'mad']\n",
    "        mae_row = subset[subset['Metric'] == 'mae']\n",
    "        r_sq_row = subset[subset['Metric'] == 'r_sq']\n",
    "        \n",
    "        # Format each cell as \"Median\\n(IQR)\" or empty if not available\n",
    "        rmse_value = f\"{rmse_row['Median'].values[0]:.4f}\\n({rmse_row['IQR'].values[0]:.4f})\" if not rmse_row.empty else \"\"\n",
    "        mad_value = f\"{mad_row['Median'].values[0]:.4f}\\n({mad_row['IQR'].values[0]:.4f})\" if not mad_row.empty else \"\"\n",
    "        mae_value = f\"{mae_row['Median'].values[0]:.4f}\\n({mae_row['IQR'].values[0]:.4f})\" if not mae_row.empty else \"\"\n",
    "        r_sq_value = f\"{r_sq_row['Median'].values[0]:.4f}\\n({r_sq_row['IQR'].values[0]:.4f})\" if not r_sq_row.empty else \"\"\n",
    "        \n",
    "        # Append combined Median\\n(IQR) values for this horizon\n",
    "        row.extend([rmse_value, mad_value, mae_value, r_sq_value])\n",
    "    \n",
    "    # Add the row to the table structure\n",
    "    table_rows.append(row)\n",
    "\n",
    "# Define the column headers, including R^2 for each horizon\n",
    "columns = [\n",
    "    \"Model\", \"RMSE (h=1)\", \"MAD (h=1)\", \"MAE (h=1)\", \"R^2 (h=1)\",\n",
    "    \"RMSE (h=3)\", \"MAD (h=3)\", \"MAE (h=3)\", \"R^2 (h=3)\", \n",
    "    \"RMSE (h=6)\", \"MAD (h=6)\", \"MAE (h=6)\", \"R^2 (h=6)\", \n",
    "    \"RMSE (h=9)\", \"MAD (h=9)\", \"MAE (h=9)\", \"R^2 (h=9)\"\n",
    "]\n",
    "\n",
    "# Create the formatted DataFrame\n",
    "formatted_table = pd.DataFrame(table_rows, columns=columns)\n",
    "\n",
    "# Define the output file path\n",
    "output_path = './graph_pdc_gt/final_formatted_output.xlsx'  # Update this path if necessary\n",
    "\n",
    "# Save the formatted table to Excel\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    formatted_table.to_excel(writer, sheet_name='Formatted_Output', index=False)\n",
    "\n",
    "print(\"Final output saved as 'final_formatted_output.xlsx' in the 'graph_pdc_off' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to sorted_metrics_summary.xlsx in the 'graph_pdc_off' directory with four decimal places for Median and IQR\n",
      "Final output saved as 'final_formatted_output.xlsx' in the 'graph_pdc_gt_off' directory.\n"
     ]
    }
   ],
   "source": [
    "### pdc gt +official \n",
    "\n",
    "\n",
    "# Necessary imports\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Ensure the directory exists\n",
    "output_dir = './graph_pdc_gt_off'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load the updated CSV file\n",
    "file_path = './graph_pdc_gt_off/combined_metrics_summary.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Multiply 'Median' and 'IQR' by 100 for better visibility, excluding r_sq\n",
    "metrics_to_scale = ['Median', 'IQR']\n",
    "for metric in metrics_to_scale:\n",
    "    data.loc[data['Metric'] != 'r_sq', metric] = data.loc[data['Metric'] != 'r_sq', metric] * 100\n",
    "\n",
    "# Round 'Median' and 'IQR' to four decimal places for better visibility\n",
    "data['Median'] = data['Median'].round(4)\n",
    "data['IQR'] = data['IQR'].round(4)\n",
    "\n",
    "# Sort the data by 'Metric', 'Horizon', and 'Median'\n",
    "sorted_data_per_metric = data.sort_values(by=['Metric', 'Horizon', 'Median']).reset_index(drop=True)\n",
    "\n",
    "# Group by 'Metric' and 'Horizon' and find the best model (minimum Median) for each metric and horizon combination\n",
    "best_models_per_metric_horizon = sorted_data_per_metric.loc[sorted_data_per_metric.groupby(['Metric', 'Horizon'])['Median'].idxmin()]\n",
    "\n",
    "# Save the outputs to an Excel file with two sheets, including the four-decimal rounded values\n",
    "output_path = f\"{output_dir}/sorted_metrics_summary.xlsx\"\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    sorted_data_per_metric.to_excel(writer, sheet_name='Sorted_Data', index=False)\n",
    "    best_models_per_metric_horizon.to_excel(writer, sheet_name='Best_Models', index=False)\n",
    "\n",
    "print(\"Data saved to sorted_metrics_summary.xlsx in the 'graph_pdc_off' directory with four decimal places for Median and IQR\")\n",
    "\n",
    "# Load the Excel file and read the \"Sorted_Data\" sheet\n",
    "file_path = './graph_pdc_gt_off/sorted_metrics_summary.xlsx'  # Update this path if necessary\n",
    "sorted_data = pd.read_excel(file_path, sheet_name='Sorted_Data')\n",
    "\n",
    "# Define empty lists to populate the new table structure\n",
    "table_rows = []\n",
    "\n",
    "# Iterate over each unique model and horizon combination to create the formatted rows\n",
    "for model in sorted_data['Model'].unique():\n",
    "    row = [model]  # Start with the model name\n",
    "    for horizon in ['tau_1', 'tau_3', 'tau_6', 'tau_9']:  # Include tau_1, tau_3, tau_6, tau_9\n",
    "        # Filter data for the specific model and horizon\n",
    "        subset = sorted_data[(sorted_data['Model'] == model) & (sorted_data['Horizon'] == horizon)]\n",
    "        \n",
    "        # Extract RMSE, MAD, MAE, and R^2 if available\n",
    "        rmse_row = subset[subset['Metric'] == 'rmse']\n",
    "        mad_row = subset[subset['Metric'] == 'mad']\n",
    "        mae_row = subset[subset['Metric'] == 'mae']\n",
    "        r_sq_row = subset[subset['Metric'] == 'r_sq']\n",
    "        \n",
    "        # Format each cell as \"Median\\n(IQR)\" or empty if not available\n",
    "        rmse_value = f\"{rmse_row['Median'].values[0]:.4f}\\n({rmse_row['IQR'].values[0]:.4f})\" if not rmse_row.empty else \"\"\n",
    "        mad_value = f\"{mad_row['Median'].values[0]:.4f}\\n({mad_row['IQR'].values[0]:.4f})\" if not mad_row.empty else \"\"\n",
    "        mae_value = f\"{mae_row['Median'].values[0]:.4f}\\n({mae_row['IQR'].values[0]:.4f})\" if not mae_row.empty else \"\"\n",
    "        r_sq_value = f\"{r_sq_row['Median'].values[0]:.4f}\\n({r_sq_row['IQR'].values[0]:.4f})\" if not r_sq_row.empty else \"\"\n",
    "        \n",
    "        # Append combined Median\\n(IQR) values for this horizon\n",
    "        row.extend([rmse_value, mad_value, mae_value, r_sq_value])\n",
    "    \n",
    "    # Add the row to the table structure\n",
    "    table_rows.append(row)\n",
    "\n",
    "# Define the column headers, including R^2 for each horizon\n",
    "columns = [\n",
    "    \"Model\", \"RMSE (h=1)\", \"MAD (h=1)\", \"MAE (h=1)\", \"R^2 (h=1)\",\n",
    "    \"RMSE (h=3)\", \"MAD (h=3)\", \"MAE (h=3)\", \"R^2 (h=3)\", \n",
    "    \"RMSE (h=6)\", \"MAD (h=6)\", \"MAE (h=6)\", \"R^2 (h=6)\", \n",
    "    \"RMSE (h=9)\", \"MAD (h=9)\", \"MAE (h=9)\", \"R^2 (h=9)\"\n",
    "]\n",
    "\n",
    "# Create the formatted DataFrame\n",
    "formatted_table = pd.DataFrame(table_rows, columns=columns)\n",
    "\n",
    "# Define the output file path\n",
    "output_path = './graph_pdc_gt_off/final_formatted_output.xlsx'  # Update this path if necessary\n",
    "\n",
    "# Save the formatted table to Excel\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    formatted_table.to_excel(writer, sheet_name='Formatted_Output', index=False)\n",
    "\n",
    "print(\"Final output saved as 'final_formatted_output.xlsx' in the 'graph_pdc_gt_off' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to sorted_metrics_summary.xlsx in the 'graph_pdc_off' directory with four decimal places for Median and IQR\n",
      "Final output saved as 'final_formatted_output.xlsx' in the 'graph_pdc_off' directory.\n"
     ]
    }
   ],
   "source": [
    "### automl official  \n",
    "\n",
    "# Necessary imports\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Ensure the directory exists\n",
    "output_dir = './graph_h2o_off'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load the updated CSV file\n",
    "file_path = './graph_h2o_off/combined_metrics_summary.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Multiply 'Median' and 'IQR' by 100 for better visibility\n",
    "data['Median'] = data['Median'] * 100\n",
    "data['IQR'] = data['IQR'] * 100\n",
    "\n",
    "# Round 'Median' and 'IQR' to four decimal places for better visibility\n",
    "data['Median'] = data['Median'].round(4)\n",
    "data['IQR'] = data['IQR'].round(4)\n",
    "\n",
    "# Sort the data by 'Metric', 'Horizon', and 'Median'\n",
    "sorted_data_per_metric = data.sort_values(by=['Metric', 'Horizon', 'Median']).reset_index(drop=True)\n",
    "\n",
    "# Group by 'Metric' and 'Horizon' and find the best model (minimum Median) for each metric and horizon combination\n",
    "best_models_per_metric_horizon = sorted_data_per_metric.loc[sorted_data_per_metric.groupby(['Metric', 'Horizon'])['Median'].idxmin()]\n",
    "\n",
    "# Save the outputs to an Excel file with two sheets, including the four-decimal rounded values\n",
    "output_path = f\"{output_dir}/sorted_metrics_summary.xlsx\"\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    sorted_data_per_metric.to_excel(writer, sheet_name='Sorted_Data', index=False)\n",
    "    best_models_per_metric_horizon.to_excel(writer, sheet_name='Best_Models', index=False)\n",
    "\n",
    "print(\"Data saved to sorted_metrics_summary.xlsx in the 'graph_pdc_off' directory with four decimal places for Median and IQR\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Necessary imports\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file and read the \"Sorted_Data\" sheet\n",
    "file_path = './graph_h2o_off/sorted_metrics_summary.xlsx'  # Update this path if necessary\n",
    "sorted_data = pd.read_excel(file_path, sheet_name='Sorted_Data')\n",
    "\n",
    "# Define empty lists to populate the new table structure\n",
    "table_rows = []\n",
    "\n",
    "# Iterate over each unique model and horizon combination to create the formatted rows\n",
    "for model in sorted_data['Model'].unique():\n",
    "    row = [model]  # Start with the model name\n",
    "    for horizon in ['tau_1', 'tau_3', 'tau_6', 'tau_9']:  # Include tau_1, tau_3, tau_6, tau_9\n",
    "        # Filter data for the specific model and horizon\n",
    "        subset = sorted_data[(sorted_data['Model'] == model) & (sorted_data['Horizon'] == horizon)]\n",
    "        \n",
    "        # Extract RMSE, MAD, and MAE if available\n",
    "        rmse_row = subset[subset['Metric'] == 'rmse']\n",
    "        mad_row = subset[subset['Metric'] == 'mad']\n",
    "        mae_row = subset[subset['Metric'] == 'mae']\n",
    "        \n",
    "        # Format each cell as \"Median\\n(IQR)\" or empty if not available\n",
    "        rmse_value = f\"{rmse_row['Median'].values[0]:.4f}\\n({rmse_row['IQR'].values[0]:.4f})\" if not rmse_row.empty else \"\"\n",
    "        mad_value = f\"{mad_row['Median'].values[0]:.4f}\\n({mad_row['IQR'].values[0]:.4f})\" if not mad_row.empty else \"\"\n",
    "        mae_value = f\"{mae_row['Median'].values[0]:.4f}\\n({mae_row['IQR'].values[0]:.4f})\" if not mae_row.empty else \"\"\n",
    "        \n",
    "        # Append combined Median\\n(IQR) values for this horizon\n",
    "        row.extend([rmse_value, mad_value, mae_value])\n",
    "    \n",
    "    # Add the row to the table structure\n",
    "    table_rows.append(row)\n",
    "\n",
    "# Define the column headers based on the structure in the image, with RMSE, MAD, and MAE for each horizon\n",
    "columns = [\n",
    "    \"Model\", \"RMSE (h=1)\", \"MAD (h=1)\", \"MAE (h=1)\", \n",
    "    \"RMSE (h=3)\", \"MAD (h=3)\", \"MAE (h=3)\", \n",
    "    \"RMSE (h=6)\", \"MAD (h=6)\", \"MAE (h=6)\", \n",
    "    \"RMSE (h=9)\", \"MAD (h=9)\", \"MAE (h=9)\"\n",
    "]\n",
    "\n",
    "# Create the formatted DataFrame\n",
    "formatted_table = pd.DataFrame(table_rows, columns=columns)\n",
    "\n",
    "# Define the output file path\n",
    "output_path = './graph_h2o_off/final_formatted_output.xlsx'  # Update this path if necessary\n",
    "\n",
    "# Save the formatted table to Excel\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    formatted_table.to_excel(writer, sheet_name='Formatted_Output', index=False)\n",
    "\n",
    "print(\"Final output saved as 'final_formatted_output.xlsx' in the 'graph_pdc_off' directory.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to sorted_metrics_summary.xlsx in the 'graph_pdc_off' directory with four decimal places for Median and IQR\n",
      "Final output saved as 'final_formatted_output.xlsx' in the 'graph_pdc_off' directory.\n"
     ]
    }
   ],
   "source": [
    "### automl gt\n",
    "\n",
    "# Necessary imports\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Ensure the directory exists\n",
    "output_dir = './graph_h2o_gt'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load the updated CSV file\n",
    "file_path = './graph_h2o_gt/combined_metrics_summary.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Multiply 'Median' and 'IQR' by 100 for better visibility\n",
    "data['Median'] = data['Median'] * 100\n",
    "data['IQR'] = data['IQR'] * 100\n",
    "\n",
    "# Round 'Median' and 'IQR' to four decimal places for better visibility\n",
    "data['Median'] = data['Median'].round(4)\n",
    "data['IQR'] = data['IQR'].round(4)\n",
    "\n",
    "# Sort the data by 'Metric', 'Horizon', and 'Median'\n",
    "sorted_data_per_metric = data.sort_values(by=['Metric', 'Horizon', 'Median']).reset_index(drop=True)\n",
    "\n",
    "# Group by 'Metric' and 'Horizon' and find the best model (minimum Median) for each metric and horizon combination\n",
    "best_models_per_metric_horizon = sorted_data_per_metric.loc[sorted_data_per_metric.groupby(['Metric', 'Horizon'])['Median'].idxmin()]\n",
    "\n",
    "# Save the outputs to an Excel file with two sheets, including the four-decimal rounded values\n",
    "output_path = f\"{output_dir}/sorted_metrics_summary.xlsx\"\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    sorted_data_per_metric.to_excel(writer, sheet_name='Sorted_Data', index=False)\n",
    "    best_models_per_metric_horizon.to_excel(writer, sheet_name='Best_Models', index=False)\n",
    "\n",
    "print(\"Data saved to sorted_metrics_summary.xlsx in the 'graph_pdc_off' directory with four decimal places for Median and IQR\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Necessary imports\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file and read the \"Sorted_Data\" sheet\n",
    "file_path = './graph_h2o_gt/sorted_metrics_summary.xlsx'  # Update this path if necessary\n",
    "sorted_data = pd.read_excel(file_path, sheet_name='Sorted_Data')\n",
    "\n",
    "# Define empty lists to populate the new table structure\n",
    "table_rows = []\n",
    "\n",
    "# Iterate over each unique model and horizon combination to create the formatted rows\n",
    "for model in sorted_data['Model'].unique():\n",
    "    row = [model]  # Start with the model name\n",
    "    for horizon in ['tau_1', 'tau_3', 'tau_6', 'tau_9']:  # Include tau_1, tau_3, tau_6, tau_9\n",
    "        # Filter data for the specific model and horizon\n",
    "        subset = sorted_data[(sorted_data['Model'] == model) & (sorted_data['Horizon'] == horizon)]\n",
    "        \n",
    "        # Extract RMSE, MAD, and MAE if available\n",
    "        rmse_row = subset[subset['Metric'] == 'rmse']\n",
    "        mad_row = subset[subset['Metric'] == 'mad']\n",
    "        mae_row = subset[subset['Metric'] == 'mae']\n",
    "        \n",
    "        # Format each cell as \"Median\\n(IQR)\" or empty if not available\n",
    "        rmse_value = f\"{rmse_row['Median'].values[0]:.4f}\\n({rmse_row['IQR'].values[0]:.4f})\" if not rmse_row.empty else \"\"\n",
    "        mad_value = f\"{mad_row['Median'].values[0]:.4f}\\n({mad_row['IQR'].values[0]:.4f})\" if not mad_row.empty else \"\"\n",
    "        mae_value = f\"{mae_row['Median'].values[0]:.4f}\\n({mae_row['IQR'].values[0]:.4f})\" if not mae_row.empty else \"\"\n",
    "        \n",
    "        # Append combined Median\\n(IQR) values for this horizon\n",
    "        row.extend([rmse_value, mad_value, mae_value])\n",
    "    \n",
    "    # Add the row to the table structure\n",
    "    table_rows.append(row)\n",
    "\n",
    "# Define the column headers based on the structure in the image, with RMSE, MAD, and MAE for each horizon\n",
    "columns = [\n",
    "    \"Model\", \"RMSE (h=1)\", \"MAD (h=1)\", \"MAE (h=1)\", \n",
    "    \"RMSE (h=3)\", \"MAD (h=3)\", \"MAE (h=3)\", \n",
    "    \"RMSE (h=6)\", \"MAD (h=6)\", \"MAE (h=6)\", \n",
    "    \"RMSE (h=9)\", \"MAD (h=9)\", \"MAE (h=9)\"\n",
    "]\n",
    "\n",
    "# Create the formatted DataFrame\n",
    "formatted_table = pd.DataFrame(table_rows, columns=columns)\n",
    "\n",
    "# Define the output file path\n",
    "output_path = './graph_h2o_gt/final_formatted_output.xlsx'  # Update this path if necessary\n",
    "\n",
    "# Save the formatted table to Excel\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    formatted_table.to_excel(writer, sheet_name='Formatted_Output', index=False)\n",
    "\n",
    "print(\"Final output saved as 'final_formatted_output.xlsx' in the 'graph_pdc_off' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to sorted_metrics_summary.xlsx in the 'graph_pdc_off' directory with four decimal places for Median and IQR\n",
      "Final output saved as 'final_formatted_output.xlsx' in the 'graph_pdc_off' directory.\n"
     ]
    }
   ],
   "source": [
    "### automl official gt \n",
    "\n",
    "# Necessary imports\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Ensure the directory exists\n",
    "output_dir = './graph_h2o_gt_off'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load the updated CSV file\n",
    "file_path = './graph_h2o_gt_off/combined_metrics_summary.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Multiply 'Median' and 'IQR' by 100 for better visibility\n",
    "data['Median'] = data['Median'] * 100\n",
    "data['IQR'] = data['IQR'] * 100\n",
    "\n",
    "# Round 'Median' and 'IQR' to four decimal places for better visibility\n",
    "data['Median'] = data['Median'].round(4)\n",
    "data['IQR'] = data['IQR'].round(4)\n",
    "\n",
    "# Sort the data by 'Metric', 'Horizon', and 'Median'\n",
    "sorted_data_per_metric = data.sort_values(by=['Metric', 'Horizon', 'Median']).reset_index(drop=True)\n",
    "\n",
    "# Group by 'Metric' and 'Horizon' and find the best model (minimum Median) for each metric and horizon combination\n",
    "best_models_per_metric_horizon = sorted_data_per_metric.loc[sorted_data_per_metric.groupby(['Metric', 'Horizon'])['Median'].idxmin()]\n",
    "\n",
    "# Save the outputs to an Excel file with two sheets, including the four-decimal rounded values\n",
    "output_path = f\"{output_dir}/sorted_metrics_summary.xlsx\"\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    sorted_data_per_metric.to_excel(writer, sheet_name='Sorted_Data', index=False)\n",
    "    best_models_per_metric_horizon.to_excel(writer, sheet_name='Best_Models', index=False)\n",
    "\n",
    "print(\"Data saved to sorted_metrics_summary.xlsx in the 'graph_pdc_off' directory with four decimal places for Median and IQR\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Necessary imports\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file and read the \"Sorted_Data\" sheet\n",
    "file_path = './graph_h2o_gt_off/sorted_metrics_summary.xlsx'  # Update this path if necessary\n",
    "sorted_data = pd.read_excel(file_path, sheet_name='Sorted_Data')\n",
    "\n",
    "# Define empty lists to populate the new table structure\n",
    "table_rows = []\n",
    "\n",
    "# Iterate over each unique model and horizon combination to create the formatted rows\n",
    "for model in sorted_data['Model'].unique():\n",
    "    row = [model]  # Start with the model name\n",
    "    for horizon in ['tau_1', 'tau_3', 'tau_6', 'tau_9']:  # Include tau_1, tau_3, tau_6, tau_9\n",
    "        # Filter data for the specific model and horizon\n",
    "        subset = sorted_data[(sorted_data['Model'] == model) & (sorted_data['Horizon'] == horizon)]\n",
    "        \n",
    "        # Extract RMSE, MAD, and MAE if available\n",
    "        rmse_row = subset[subset['Metric'] == 'rmse']\n",
    "        mad_row = subset[subset['Metric'] == 'mad']\n",
    "        mae_row = subset[subset['Metric'] == 'mae']\n",
    "        \n",
    "        # Format each cell as \"Median\\n(IQR)\" or empty if not available\n",
    "        rmse_value = f\"{rmse_row['Median'].values[0]:.4f}\\n({rmse_row['IQR'].values[0]:.4f})\" if not rmse_row.empty else \"\"\n",
    "        mad_value = f\"{mad_row['Median'].values[0]:.4f}\\n({mad_row['IQR'].values[0]:.4f})\" if not mad_row.empty else \"\"\n",
    "        mae_value = f\"{mae_row['Median'].values[0]:.4f}\\n({mae_row['IQR'].values[0]:.4f})\" if not mae_row.empty else \"\"\n",
    "        \n",
    "        # Append combined Median\\n(IQR) values for this horizon\n",
    "        row.extend([rmse_value, mad_value, mae_value])\n",
    "    \n",
    "    # Add the row to the table structure\n",
    "    table_rows.append(row)\n",
    "\n",
    "# Define the column headers based on the structure in the image, with RMSE, MAD, and MAE for each horizon\n",
    "columns = [\n",
    "    \"Model\", \"RMSE (h=1)\", \"MAD (h=1)\", \"MAE (h=1)\", \n",
    "    \"RMSE (h=3)\", \"MAD (h=3)\", \"MAE (h=3)\", \n",
    "    \"RMSE (h=6)\", \"MAD (h=6)\", \"MAE (h=6)\", \n",
    "    \"RMSE (h=9)\", \"MAD (h=9)\", \"MAE (h=9)\"\n",
    "]\n",
    "\n",
    "# Create the formatted DataFrame\n",
    "formatted_table = pd.DataFrame(table_rows, columns=columns)\n",
    "\n",
    "# Define the output file path\n",
    "output_path = './graph_h2o_gt_off/final_formatted_output.xlsx'  # Update this path if necessary\n",
    "\n",
    "# Save the formatted table to Excel\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    formatted_table.to_excel(writer, sheet_name='Formatted_Output', index=False)\n",
    "\n",
    "print(\"Final output saved as 'final_formatted_output.xlsx' in the 'graph_pdc_off' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined output saved as 'combined_final_output.xlsx' in the './graph_pdc_off' directory.\n"
     ]
    }
   ],
   "source": [
    "### official \n",
    "\n",
    "# Necessary imports\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the file paths for the two Excel files to be combined\n",
    "file_path1 = './graph_pdc_off/final_formatted_output.xlsx'\n",
    "file_path2 = './graph_h2o_off/final_formatted_output.xlsx'\n",
    "\n",
    "# Read both Excel files into DataFrames\n",
    "df1 = pd.read_excel(file_path1, sheet_name='Formatted_Output')\n",
    "df2 = pd.read_excel(file_path2, sheet_name='Formatted_Output')\n",
    "\n",
    "# Combine the DataFrames by rows\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_dir = './graph_pdc_off'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define the output file path\n",
    "output_path = os.path.join(output_dir, 'combined_final_output.xlsx')\n",
    "\n",
    "# Save the combined DataFrame to an Excel file\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    combined_df.to_excel(writer, sheet_name='Combined_Output', index=False)\n",
    "\n",
    "print(f\"Combined output saved as 'combined_final_output.xlsx' in the '{output_dir}' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined output saved as 'combined_final_output.xlsx' in the './graph_pdc_gt' directory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### GT\n",
    "\n",
    "# Necessary imports\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the file paths for the two Excel files to be combined\n",
    "file_path1 = './graph_pdc_gt/final_formatted_output.xlsx'\n",
    "file_path2 = './graph_h2o_gt/final_formatted_output.xlsx'\n",
    "\n",
    "# Read both Excel files into DataFrames\n",
    "df1 = pd.read_excel(file_path1, sheet_name='Formatted_Output')\n",
    "df2 = pd.read_excel(file_path2, sheet_name='Formatted_Output')\n",
    "\n",
    "# Combine the DataFrames by rows\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_dir = './graph_pdc_gt'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define the output file path\n",
    "output_path = os.path.join(output_dir, 'combined_final_output.xlsx')\n",
    "\n",
    "# Save the combined DataFrame to an Excel file\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    combined_df.to_excel(writer, sheet_name='Combined_Output', index=False)\n",
    "\n",
    "print(f\"Combined output saved as 'combined_final_output.xlsx' in the '{output_dir}' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined output saved as 'combined_final_output.xlsx' in the './graph_pdc_gt_off' directory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## official and gt \n",
    "\n",
    "# Necessary imports\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the file paths for the two Excel files to be combined\n",
    "file_path1 = './graph_pdc_gt_off/final_formatted_output.xlsx'\n",
    "file_path2 = './graph_h2o_gt_off/final_formatted_output.xlsx'\n",
    "\n",
    "# Read both Excel files into DataFrames\n",
    "df1 = pd.read_excel(file_path1, sheet_name='Formatted_Output')\n",
    "df2 = pd.read_excel(file_path2, sheet_name='Formatted_Output')\n",
    "\n",
    "# Combine the DataFrames by rows\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_dir = './graph_pdc_gt_off'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define the output file path\n",
    "output_path = os.path.join(output_dir, 'combined_final_output.xlsx')\n",
    "\n",
    "# Save the combined DataFrame to an Excel file\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    combined_df.to_excel(writer, sheet_name='Combined_Output', index=False)\n",
    "\n",
    "print(f\"Combined output saved as 'combined_final_output.xlsx' in the '{output_dir}' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './graph_pdc_off/combined_final_output-official.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 12\u001b[0m\n\u001b[0;32m      5\u001b[0m file_paths \u001b[39m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcombined_final_output-official\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m./graph_pdc_off/combined_final_output-official.xlsx\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcombined_final_output-official_GT\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m./graph_pdc_gt_off/combined_final_output-official_GT.xlsx\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcombined_final_output-GT\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m./graph_pdc_gt/combined_final_output-GT.xlsx\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m }\n\u001b[0;32m     11\u001b[0m \u001b[39m# Load the files into DataFrames\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m dataframes \u001b[39m=\u001b[39m {name: pd\u001b[39m.\u001b[39mread_excel(path) \u001b[39mfor\u001b[39;00m name, path \u001b[39min\u001b[39;00m file_paths\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m     14\u001b[0m \u001b[39m# Define the horizons to analyze based on RMSE columns\u001b[39;00m\n\u001b[0;32m     15\u001b[0m horizons \u001b[39m=\u001b[39m [col \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m dataframes[\u001b[39m\"\u001b[39m\u001b[39mcombined_final_output-official\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mcolumns \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mRMSE\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m col]\n",
      "Cell \u001b[1;32mIn[4], line 12\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m file_paths \u001b[39m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcombined_final_output-official\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m./graph_pdc_off/combined_final_output-official.xlsx\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcombined_final_output-official_GT\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m./graph_pdc_gt_off/combined_final_output-official_GT.xlsx\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcombined_final_output-GT\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m./graph_pdc_gt/combined_final_output-GT.xlsx\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m }\n\u001b[0;32m     11\u001b[0m \u001b[39m# Load the files into DataFrames\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m dataframes \u001b[39m=\u001b[39m {name: pd\u001b[39m.\u001b[39;49mread_excel(path) \u001b[39mfor\u001b[39;00m name, path \u001b[39min\u001b[39;00m file_paths\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m     14\u001b[0m \u001b[39m# Define the horizons to analyze based on RMSE columns\u001b[39;00m\n\u001b[0;32m     15\u001b[0m horizons \u001b[39m=\u001b[39m [col \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m dataframes[\u001b[39m\"\u001b[39m\u001b[39mcombined_final_output-official\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mcolumns \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mRMSE\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m col]\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\Langchain\\lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[39m=\u001b[39m ExcelFile(\n\u001b[0;32m    496\u001b[0m         io,\n\u001b[0;32m    497\u001b[0m         storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    498\u001b[0m         engine\u001b[39m=\u001b[39;49mengine,\n\u001b[0;32m    499\u001b[0m         engine_kwargs\u001b[39m=\u001b[39;49mengine_kwargs,\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    501\u001b[0m \u001b[39melif\u001b[39;00m engine \u001b[39mand\u001b[39;00m engine \u001b[39m!=\u001b[39m io\u001b[39m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEngine should not be specified when passing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\Langchain\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     ext \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxls\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1549\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1550\u001b[0m     ext \u001b[39m=\u001b[39m inspect_excel_format(\n\u001b[0;32m   1551\u001b[0m         content_or_path\u001b[39m=\u001b[39;49mpath_or_buffer, storage_options\u001b[39m=\u001b[39;49mstorage_options\n\u001b[0;32m   1552\u001b[0m     )\n\u001b[0;32m   1553\u001b[0m     \u001b[39mif\u001b[39;00m ext \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1555\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExcel file format cannot be determined, you must specify \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1556\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39man engine manually.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1557\u001b[0m         )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\Langchain\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(content_or_path, \u001b[39mbytes\u001b[39m):\n\u001b[0;32m   1400\u001b[0m     content_or_path \u001b[39m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1402\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m   1403\u001b[0m     content_or_path, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m, storage_options\u001b[39m=\u001b[39;49mstorage_options, is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m   1404\u001b[0m ) \u001b[39mas\u001b[39;00m handle:\n\u001b[0;32m   1405\u001b[0m     stream \u001b[39m=\u001b[39m handle\u001b[39m.\u001b[39mhandle\n\u001b[0;32m   1406\u001b[0m     stream\u001b[39m.\u001b[39mseek(\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\Langchain\\lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[0;32m    883\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './graph_pdc_off/combined_final_output-official.xlsx'"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Define the file paths\n",
    "file_paths = {\n",
    "    \"combined_final_output-official\": \"./graph_pdc_off/combined_final_output-official.xlsx\",\n",
    "    \"combined_final_output-official_GT\": \"./graph_pdc_gt_off/combined_final_output-official_GT.xlsx\",\n",
    "    \"combined_final_output-GT\": \"./graph_pdc_gt/combined_final_output-GT.xlsx\"\n",
    "}\n",
    "\n",
    "# Load the files into DataFrames\n",
    "dataframes = {name: pd.read_excel(path) for name, path in file_paths.items()}\n",
    "\n",
    "# Define the horizons to analyze based on RMSE columns\n",
    "horizons = [col for col in dataframes[\"combined_final_output-official\"].columns if 'RMSE' in col]\n",
    "\n",
    "# Function to find the first and second lowest RMSE values with model information\n",
    "def find_first_second_lowest_rmse(df, horizons):\n",
    "    # Results storage\n",
    "    results = []\n",
    "    groups = df['Group'].unique()\n",
    "    for group in groups[:2]:  # Analyze only the first two groups\n",
    "        group_df = df[df['Group'] == group]\n",
    "        for horizon in horizons:\n",
    "            # Sort by RMSE to get the models with the lowest values\n",
    "            sorted_rmse = group_df.sort_values(by=horizon)[['Model', horizon]].dropna().head(2)\n",
    "            rmse_info = sorted_rmse[horizon].values\n",
    "            model_info = sorted_rmse['Model'].values\n",
    "            results.append({\n",
    "                \"Group\": group,\n",
    "                \"Horizon\": horizon,\n",
    "                \"First Lowest RMSE Model\": model_info[0] if len(model_info) > 0 else None,\n",
    "                \"First Lowest RMSE Value\": rmse_info[0] if len(rmse_info) > 0 else None,\n",
    "                \"Second Lowest RMSE Model\": model_info[1] if len(model_info) > 1 else None,\n",
    "                \"Second Lowest RMSE Value\": rmse_info[1] if len(rmse_info) > 1 else None,\n",
    "            })\n",
    "    return results\n",
    "\n",
    "# Collect results for each file\n",
    "all_results = []\n",
    "for name, df in dataframes.items():\n",
    "    results = find_first_second_lowest_rmse(df, horizons)\n",
    "    for result in results:\n",
    "        result[\"File\"] = name\n",
    "        all_results.append(result)\n",
    "\n",
    "# Convert the final results to a DataFrame\n",
    "final_output_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a new Excel file\n",
    "output_path = \"./graph_pdc_off/final_first_second_lowest_rmse_output.xlsx\"\n",
    "final_output_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(\"Analysis complete. Results saved to:\", output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
